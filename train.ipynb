{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BHZnXywjxGeq"
   },
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /home/ubuntu/.local/lib/python3.8/site-packages (23.1.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/ubuntu/.local/lib/python3.8/site-packages (2.0.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch) (2.4)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (45.2.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.34.2)\n",
      "Requirement already satisfied: cmake in /home/ubuntu/.local/lib/python3.8/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/ubuntu/.local/lib/python3.8/site-packages (from triton==2.0.0->torch) (16.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.local/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip\n",
    "!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kY_j8RUDP5y4"
   },
   "outputs": [],
   "source": [
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math\n",
    "from torch.autograd.variable import Variable\n",
    "import typing\n",
    "import random\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y4lRdOSZNpe2"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ph2WO5JpKukk",
    "outputId": "ab00d895-307a-4ade-e705-1c6dd8ae6926"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "modelname=\"4_22_23_m1\"\n",
    "\n",
    "prefix_models=\"models/\"+modelname+\"/\"\n",
    "\n",
    "if not os.path.exists(prefix_models):\n",
    "    os.makedirs(prefix_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Oe3wtt5oADl6"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xGOoJdNdRSaO"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        #mine is [batch, seq, embed]\n",
    "        x = x.permute((1,0,2))\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        dropout = self.dropout(x)\n",
    "        return dropout.permute((1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XakHZ4HfFdYM"
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        key_tp = key.transpose(-2, -1)\n",
    "\n",
    "        scores = query.matmul(key_tp) / math.sqrt(query.size()[-1])\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "            \n",
    "        attention = F.softmax(scores, dim = -1)\n",
    "\n",
    "        return attention.matmul(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "G-sb6gd7L5bR"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 head_num,\n",
    "                 bias=True,\n",
    "                 activation=F.relu):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        if in_features % head_num != 0:\n",
    "            raise ValueError('`in_features`({}) should be divisible by \\\n",
    "                `head_num`({})'.format(in_features, head_num))\n",
    "        self.in_features = in_features\n",
    "        self.head_num = head_num\n",
    "        self.activation = activation\n",
    "        self.bias = bias\n",
    "        self.linear_q = nn.Linear(in_features, in_features, bias)\n",
    "        self.linear_k = nn.Linear(in_features, in_features, bias)\n",
    "        self.linear_v = nn.Linear(in_features, in_features, bias)\n",
    "        self.linear_o = nn.Linear(in_features, in_features, bias)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        q, k, v = self.linear_q(q), self.linear_k(k), self.linear_v(v)\n",
    "        if self.activation is not None:\n",
    "            q = self.activation(q)\n",
    "            k = self.activation(k)\n",
    "            v = self.activation(v)\n",
    "\n",
    "        q = self._reshape_to_batches(q)\n",
    "        k = self._reshape_to_batches(k)\n",
    "        v = self._reshape_to_batches(v)\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = mask.repeat(self.head_num, 1, 1)   \n",
    "        \n",
    "        y = ScaledDotProductAttention()(q, k, v, mask)        \n",
    "        \n",
    "        y = self._reshape_from_batches(y)      \n",
    "\n",
    "        y = self.linear_o(y)\n",
    "        if self.activation is not None:\n",
    "            y = self.activation(y)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def gen_causal_mask(x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        return torch.tril(torch.ones(seq_len, seq_len)).view(1, seq_len, seq_len).repeat(batch_size, 1, 1)\n",
    "\n",
    "    def _reshape_to_batches(self, x):\n",
    "        batch_size, seq_len, in_feature = x.size()\n",
    "        sub_dim = in_feature // self.head_num\n",
    "        return x.reshape(batch_size, seq_len, self.head_num, sub_dim)\\\n",
    "                .permute(0, 2, 1, 3)\\\n",
    "                .reshape(batch_size * self.head_num, seq_len, sub_dim)\n",
    "\n",
    "    def _reshape_from_batches(self, x):\n",
    "        batch_size, seq_len, in_feature = x.size()\n",
    "        batch_size //= self.head_num\n",
    "        out_dim = in_feature * self.head_num\n",
    "        return x.reshape(batch_size, self.head_num, seq_len, in_feature)\\\n",
    "                .permute(0, 2, 1, 3)\\\n",
    "                .reshape(batch_size, seq_len, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NDpTASiaTxTX"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim: int,\n",
    "                 n_self_heads: int,\n",
    "                 n_features: int,\n",
    "                 n_layers: int,\n",
    "                 n_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        #Embedding layer\n",
    "        self.embedding = nn.Embedding(n_features, embedding_dim)\n",
    "        #Positional encoding\n",
    "        self.pos_encode = PositionalEncoding(embedding_dim)\n",
    "\n",
    "        self.decoder_layers = []\n",
    "\n",
    "        for _ in range(n_layers):\n",
    "            layer = []\n",
    "            #Add multihead, which will be cross or self attention\n",
    "            layer.append(MultiHeadAttention(embedding_dim, n_self_heads)) #self attention first, masked\n",
    "            #Now add layer norm\n",
    "            layer.append(nn.LayerNorm(embedding_dim))\n",
    "            #Add a feed forward\n",
    "            layer.append(nn.Linear(embedding_dim, embedding_dim))\n",
    "            #Now add layer norm\n",
    "            layer.append(nn.LayerNorm(embedding_dim))\n",
    "\n",
    "            self.decoder_layers.append(nn.ModuleList(layer))\n",
    "        self.decoder_layers=nn.ModuleList(self.decoder_layers)\n",
    "\n",
    "        self.to_out = nn.Linear(embedding_dim, n_classes)\n",
    "            \n",
    "    def forward(self, x: torch.Tensor, calculate_loss: bool = False):\n",
    "        \"\"\"\n",
    "        Expect tensor of [batch_size, n_features]\n",
    "        \"\"\"\n",
    "        if calculate_loss:\n",
    "            #If give model that accepts ?x?x4 abcd, expect bcd0\n",
    "            \n",
    "            target_logits=torch.cat([x[:,1:], torch.zeros((x.shape[0],1)).to(device)], dim=-1) ## if x is abcd, then target_logits is bcd0\n",
    "\n",
    "        x=x.long().to(device)\n",
    "        embed = self.embedding(x)\n",
    "        pos_encode = self.pos_encode(embed)\n",
    "\n",
    "        res = embed+pos_encode\n",
    "        \n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            d_self_attention = decoder_layer[0]\n",
    "            d_layer_norm_1 = decoder_layer[1]\n",
    "            d_ff = decoder_layer[2]\n",
    "            d_layer_norm_2 = decoder_layer[3]\n",
    "            \n",
    "            ## Run the decoder\n",
    "            #do masked self attention\n",
    "            mask = MultiHeadAttention.gen_causal_mask(res).to(device)\n",
    "            res = res + d_self_attention(res,res,res, mask = mask)\n",
    "            self_res = res\n",
    "            #layer norm\n",
    "            res = d_layer_norm_1(res)\n",
    "\n",
    "            #do ff\n",
    "            res = self_res + d_ff(res)\n",
    "            #layer norm\n",
    "            res = d_layer_norm_2(res)\n",
    "\n",
    "        out = self.to_out(res)\n",
    "        if calculate_loss:\n",
    "            loss = nn.functional.cross_entropy(out.permute(0, 2, 1), target_logits.long())\n",
    "            return out,loss\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HqGGEpvCLbP8"
   },
   "outputs": [],
   "source": [
    "def tokenize_multi(text_seq: str, features: int, encoding = \"utf8\") -> torch.Tensor:\n",
    "    # tokenize the input text\n",
    "    sentences = []\n",
    "    for sentence in filter(lambda x: x!=\"\", text_seq.split(\"\\n\")):\n",
    "        base = list(bytes(sentence, \"utf8\"))\n",
    "        if len(base) < features:\n",
    "            base.extend([0] * (features - len(base)))\n",
    "        tensor = torch.Tensor(base)\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        sentences.append(tensor)\n",
    "\n",
    "    return torch.cat(sentences, dim = 0)\n",
    "\n",
    "def tokenize_single(sentence: str, features: int, encoding = \"utf8\") -> torch.Tensor:\n",
    "    base = list(bytes(sentence, \"utf8\"))\n",
    "    if len(base) < features:\n",
    "        base.extend([0] * (features - len(base)))\n",
    "    tensor = torch.Tensor(base)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pB-Xcf4TkKNQ"
   },
   "outputs": [],
   "source": [
    "def generate(seed: str, cutoff: int = 128) -> str:\n",
    "    output = torch.tensor([list(bytes(seed,\"utf8\"))]).to(device)\n",
    "    \n",
    "    res=output\n",
    "    last = -1\n",
    "    i=0\n",
    "    while last != 0 and i<cutoff:\n",
    "        res = model(output)\n",
    "        argmax=res.argmax(-1)\n",
    "        \n",
    "        out = list(output[0])\n",
    "        out.append(list(argmax.to(device)[0])[-1])\n",
    "        last = list(argmax.to(device)[0])[-1]\n",
    "        output = torch.tensor([out])\n",
    "        i+=1\n",
    "    \n",
    "    if last == 0:\n",
    "        return convert_to_str(output)\n",
    "    return convert_to_str(output)+\"<CUTOFF>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "R81mAag8mHEG"
   },
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data: typing.List[str], features):\n",
    "        self.raw_data = data\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.raw_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return tokenize_single(self.raw_data[index], self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xQidsLjVaFUi"
   },
   "outputs": [],
   "source": [
    "def convert_to_str(x: torch.Tensor) -> str:\n",
    "    #Expects [1, 256] tensor\n",
    "    bts = []\n",
    "    i=0\n",
    "    while len(bts)<x.shape[1] and x[0][i] != 0:\n",
    "        bts.append(int(x[0][i]))\n",
    "        i+=1\n",
    "    return bytes(bts).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "97rbDfS4gO8C"
   },
   "outputs": [],
   "source": [
    "n_features = 256 # No. of tokens\n",
    "embedding_dim = 640\n",
    "train_split = 0.75\n",
    "batch_size = 128\n",
    "head_factor = 64\n",
    "assert embedding_dim%head_factor == 0\n",
    "head_size = embedding_dim//head_factor\n",
    "n_layers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvvenMeUKfaj",
    "outputId": "fb38b6f5-0eaf-4d89-83ad-bee41604b8ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950424\n"
     ]
    }
   ],
   "source": [
    "path_to_data = \"data/numbers.txt\"\n",
    "data_raw = open(path_to_data, encoding=\"utf-8\").read()\n",
    "\n",
    "data_split = list(filter(lambda x: x!=\"\", data_raw.split(\"\\n\")))\n",
    "random.shuffle(data_split)\n",
    "\n",
    "n = int(train_split * len(data_split))\n",
    "print(n)\n",
    "train_data = data_split[:n]\n",
    "val_data = data_split[n:]\n",
    "\n",
    "train_dataloader = TextDataset(train_data, n_features)\n",
    "test_dataloader = TextDataset(train_data, n_features)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_dataloader, batch_size=batch_size)\n",
    "testloader = torch.utils.data.DataLoader(test_dataloader , batch_size=1)\n",
    "testloader_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GvibftHanb0A"
   },
   "outputs": [],
   "source": [
    "model = Transformer(embedding_dim, head_size, n_features, n_layers, 256)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXqmUSK0M3hD",
    "outputId": "69ad8160-d138-4e98-99b6-bd8cb83753c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "tensor([[198, 158,  39,  28, 249, 119, 161, 252, 103, 163, 197, 177, 103, 112,\n",
      "           3, 254, 138,  98,  98, 196, 175, 175, 175, 175, 175, 175, 175, 175,\n",
      "         175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175,  65, 175, 175,\n",
      "         175, 199,  65,  65,  65, 163,  65, 175,  65, 175,  65,  65,  65,  65,\n",
      "          65, 175, 175, 175, 175, 175, 175,  65,  65,  65,  65, 161, 163, 175,\n",
      "         175, 175, 175,  37, 175, 111, 175, 199, 242, 161,  81,  37,  65,  65,\n",
      "         175, 161, 175, 175, 175,  65, 148,  65,  37,  37,  37,  37,  68,  37,\n",
      "         163, 175, 163, 175,  65,  65,  65,  65,  65, 233,  65, 175, 175, 175,\n",
      "         175,  65, 242, 233,  65,  65,  65, 163,  65, 163, 163,  65,  65,  65,\n",
      "          65,  65,  65,  65,  65,  65, 175, 175, 175,  65,  65,  65,  65, 175,\n",
      "          65,  65,  65,  65,  65,  65, 175,  65,  65,  65,  65,  65, 175, 163,\n",
      "         175,  65, 233,  65,  65,  65,  65,  65,  65, 175,  65,  65,  65,  65,\n",
      "          65,  65, 175,  65, 163, 233, 163,  65, 199,  65,  65,  65,  65,  65,\n",
      "          65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         199,  65,  65, 161, 175,  65,  65, 161, 175,  65,  65,  65,  65,  65,\n",
      "          65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "          65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 175,  65,  65,  65,\n",
      "          65,  65,  65,  65, 161, 161, 175, 175,  65,  65, 175,  65, 175, 175,\n",
      "         175,  65,  65,  65]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input=next(testloader_iter)\n",
    "input=input.to(device)\n",
    "res = model(input)\n",
    "print(input.shape)\n",
    "print(res.shape)\n",
    "print(res.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tZji9Va7-unn"
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hUN0DJQo-vmf"
   },
   "outputs": [],
   "source": [
    "n_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GczR7J4u6L5Q",
    "outputId": "15259e58-4468-44ff-dcf3-6c8dfb86d6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 22 18:54:53 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10          On   | 00000000:06:00.0 Off |                    0 |\n",
      "|  0%   35C    P0    55W / 150W |   1155MiB / 23028MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    205819      C   /usr/bin/python3                 1153MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yYr65bmbITE1"
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"What is 1+2?\",\n",
    "    \"Compute 1 plus 2:\",\n",
    "    \"What is 3-2?\",\n",
    "    \"Compute 3 minus 2:\",\n",
    "    \"What is 3*4?\",\n",
    "    \"Compute 3 times 4:\",\n",
    "    \"What is 4/2?\",\n",
    "    \"Compute 4 divided by 2:\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "o85FrKyF-wg-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7426/7426 [1:15:45<00:00,  1.63it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 0: What is 1+2?\n",
      "Model output: What is 1+2? 11\n",
      "\n",
      "Prompt 1: Compute 1 plus 2:\n",
      "Model output: Compute 1 plus 2: 11\n",
      "\n",
      "Prompt 2: What is 3-2?\n",
      "Model output: What is 3-2? -1\n",
      "\n",
      "Prompt 3: Compute 3 minus 2:\n",
      "Model output: Compute 3 minus 2: -1\n",
      "\n",
      "Prompt 4: What is 3*4?\n",
      "Model output: What is 3*4? 16\n",
      "\n",
      "Prompt 5: Compute 3 times 4:\n",
      "Model output: Compute 3 times 4: 16\n",
      "\n",
      "Prompt 6: What is 4/2?\n",
      "Model output: What is 4/2? 13\n",
      "\n",
      "Prompt 7: Compute 4 divided by 2:\n",
      "Model output: Compute 4 divided by 2: 13\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1206/7426 [12:18<1:03:29,  1.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3fffb970ab35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "epoch_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    batch_losses = []\n",
    "    for data in tqdm.tqdm(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data = data.to(device)\n",
    "\n",
    "        output, loss = model(data, True)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        \n",
    "    epoch_losses.append(sum(batch_losses)/len(batch_losses))\n",
    "\n",
    "    plt.plot(range(len(batch_losses)),batch_losses)\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Batch loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(range(len(epoch_losses)), epoch_losses)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Epoch loss\")\n",
    "    plt.show()\n",
    "\n",
    "    torch.save(model, prefix_models+f\"model_E{epoch}\")\n",
    "\n",
    "    with open(prefix_models+\"losses.txt\", \"a\") as f:\n",
    "        f.write(f\"{epoch_losses[-1]}\\n\")\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            print(f\"Prompt {i}: {prompt}\")\n",
    "            output=generate(prompt)\n",
    "            print(f\"Model output: {output}\")\n",
    "            print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUracnfcZSLX"
   },
   "outputs": [],
   "source": [
    "model = torch.load(prefix_models+\"model_E9\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        print(f\"Prompt {i}: {prompt}\")\n",
    "        output=generate(prompt)\n",
    "        print(f\"Model output: {output}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "r31WSN9YiTuZ"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  What is 1+3?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: What is 1+3? 1\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  What is 1+3?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: What is 1+3? 1\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  What is 1+2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: What is 1+2? 1\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  What is 2+1?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: What is 2+1? 1\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-84713c073239>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">>> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model output: {output}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import builtins\n",
    "while True:\n",
    "    prompt = builtins.input(\">>> \")\n",
    "    output=generate(prompt)\n",
    "    print(f\"Model output: {output}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
